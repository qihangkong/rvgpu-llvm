// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple riscv64-none-linux-gnu -target-feature +zve64d \
// RUN: -target-feature +f -target-feature +d -target-feature +zvfh \
// RUN: -target-feature +zfh -disable-O0-optnone \
// RUN: -mvscale-min=4 -mvscale-max=4 -emit-llvm -o - %s | \
// RUN: opt -S -passes=sroa | FileCheck %s

// REQUIRES: riscv-registered-target

#include <riscv_vector.h>

// EQ

// CHECK-LABEL: @eq_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t eq_i8(vint8m1_t a, vint8m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t eq_i16(vint16m1_t a, vint16m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t eq_i32(vint32m1_t a, vint32m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t eq_i64(vint64m1_t a, vint64m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t eq_u8(vuint8m1_t a, vuint8m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t eq_u16(vuint16m1_t a, vuint16m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t eq_u32(vuint32m1_t a, vuint32m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t eq_u64(vuint64m1_t a, vuint64m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_f16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp oeq <vscale x 4 x half> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t eq_f16(vfloat16m1_t a, vfloat16m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_f32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp oeq <vscale x 2 x float> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t eq_f32(vfloat32m1_t a, vfloat32m1_t b) {
  return a == b;
}

// CHECK-LABEL: @eq_f64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp oeq <vscale x 1 x double> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t eq_f64(vfloat64m1_t a, vfloat64m1_t b) {
  return a == b;
}

// NEQ

// CHECK-LABEL: @neq_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ne <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t neq_i8(vint8m1_t a, vint8m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ne <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t neq_i16(vint16m1_t a, vint16m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ne <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t neq_i32(vint32m1_t a, vint32m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ne <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t neq_i64(vint64m1_t a, vint64m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ne <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t neq_u8(vuint8m1_t a, vuint8m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ne <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t neq_u16(vuint16m1_t a, vuint16m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ne <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t neq_u32(vuint32m1_t a, vuint32m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ne <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t neq_u64(vuint64m1_t a, vuint64m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_f16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp une <vscale x 4 x half> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t neq_f16(vfloat16m1_t a, vfloat16m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_f32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp une <vscale x 2 x float> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t neq_f32(vfloat32m1_t a, vfloat32m1_t b) {
  return a != b;
}

// CHECK-LABEL: @neq_f64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp une <vscale x 1 x double> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t neq_f64(vfloat64m1_t a, vfloat64m1_t b) {
  return a != b;
}

// LT

// CHECK-LABEL: @lt_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ult <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t lt_i8(vint8m1_t a, vint8m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ult <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t lt_i16(vint16m1_t a, vint16m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ult <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t lt_i32(vint32m1_t a, vint32m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ult <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t lt_i64(vint64m1_t a, vint64m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ult <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t lt_u8(vuint8m1_t a, vuint8m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ult <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t lt_u16(vuint16m1_t a, vuint16m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ult <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t lt_u32(vuint32m1_t a, vuint32m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ult <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t lt_u64(vuint64m1_t a, vuint64m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_f16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp olt <vscale x 4 x half> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t lt_f16(vfloat16m1_t a, vfloat16m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_f32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp olt <vscale x 2 x float> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t lt_f32(vfloat32m1_t a, vfloat32m1_t b) {
  return a < b;
}

// CHECK-LABEL: @lt_f64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp olt <vscale x 1 x double> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t lt_f64(vfloat64m1_t a, vfloat64m1_t b) {
  return a < b;
}

// LEQ

// CHECK-LABEL: @leq_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ule <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t leq_i8(vint8m1_t a, vint8m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ule <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t leq_i16(vint16m1_t a, vint16m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ule <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t leq_i32(vint32m1_t a, vint32m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ule <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t leq_i64(vint64m1_t a, vint64m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ule <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t leq_u8(vuint8m1_t a, vuint8m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ule <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t leq_u16(vuint16m1_t a, vuint16m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ule <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t leq_u32(vuint32m1_t a, vuint32m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ule <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t leq_u64(vuint64m1_t a, vuint64m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_f16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp ole <vscale x 4 x half> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t leq_f16(vfloat16m1_t a, vfloat16m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_f32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp ole <vscale x 2 x float> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t leq_f32(vfloat32m1_t a, vfloat32m1_t b) {
  return a <= b;
}

// CHECK-LABEL: @leq_f64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp ole <vscale x 1 x double> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t leq_f64(vfloat64m1_t a, vfloat64m1_t b) {
  return a <= b;
}

// GT

// CHECK-LABEL: @gt_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ugt <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t gt_i8(vint8m1_t a, vint8m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ugt <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t gt_i16(vint16m1_t a, vint16m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ugt <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t gt_i32(vint32m1_t a, vint32m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ugt <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t gt_i64(vint64m1_t a, vint64m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ugt <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t gt_u8(vuint8m1_t a, vuint8m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ugt <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t gt_u16(vuint16m1_t a, vuint16m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ugt <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t gt_u32(vuint32m1_t a, vuint32m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ugt <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t gt_u64(vuint64m1_t a, vuint64m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_f16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp ogt <vscale x 4 x half> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t gt_f16(vfloat16m1_t a, vfloat16m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_f32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp ogt <vscale x 2 x float> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t gt_f32(vfloat32m1_t a, vfloat32m1_t b) {
  return a > b;
}

// CHECK-LABEL: @gt_f64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp ogt <vscale x 1 x double> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t gt_f64(vfloat64m1_t a, vfloat64m1_t b) {
  return a > b;
}

// GEQ

// CHECK-LABEL: @geq_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp uge <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t geq_i8(vint8m1_t a, vint8m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp uge <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t geq_i16(vint16m1_t a, vint16m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp uge <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t geq_i32(vint32m1_t a, vint32m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp uge <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t geq_i64(vint64m1_t a, vint64m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp uge <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 8 x i1> [[CMP]] to <vscale x 8 x i8>
// CHECK-NEXT:    ret <vscale x 8 x i8> [[CONV]]
//
vint8m1_t geq_u8(vuint8m1_t a, vuint8m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp uge <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t geq_u16(vuint16m1_t a, vuint16m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp uge <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t geq_u32(vuint32m1_t a, vuint32m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp uge <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t geq_u64(vuint64m1_t a, vuint64m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_f16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp oge <vscale x 4 x half> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 4 x i1> [[CMP]] to <vscale x 4 x i16>
// CHECK-NEXT:    ret <vscale x 4 x i16> [[CONV]]
//
vint16m1_t geq_f16(vfloat16m1_t a, vfloat16m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_f32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp oge <vscale x 2 x float> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 2 x i1> [[CMP]] to <vscale x 2 x i32>
// CHECK-NEXT:    ret <vscale x 2 x i32> [[CONV]]
//
vint32m1_t geq_f32(vfloat32m1_t a, vfloat32m1_t b) {
  return a >= b;
}

// CHECK-LABEL: @geq_f64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = fcmp oge <vscale x 1 x double> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    [[CONV:%.*]] = zext <vscale x 1 x i1> [[CMP]] to <vscale x 1 x i64>
// CHECK-NEXT:    ret <vscale x 1 x i64> [[CONV]]
//
vint64m1_t geq_f64(vfloat64m1_t a, vfloat64m1_t b) {
  return a >= b;
}

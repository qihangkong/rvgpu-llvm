// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple riscv64-none-linux-gnu -target-feature +zve64d \
// RUN: -target-feature +f -target-feature +d -disable-O0-optnone \
// RUN: -mvscale-min=4 -mvscale-max=4 -emit-llvm -o - %s | \
// RUN: opt -S -passes=sroa | FileCheck %s

// REQUIRES: riscv-registered-target

#include <riscv_vector.h>

// AND

// CHECK-LABEL: @and_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[AND:%.*]] = and <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 8 x i8> [[AND]]
//
vint8m1_t and_i8(vint8m1_t a, vint8m1_t b) {
  return a & b;
}

// CHECK-LABEL: @and_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[AND:%.*]] = and <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 4 x i16> [[AND]]
//
vint16m1_t and_i16(vint16m1_t a, vint16m1_t b) {
  return a & b;
}

// CHECK-LABEL: @and_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[AND:%.*]] = and <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 2 x i32> [[AND]]
//
vint32m1_t and_i32(vint32m1_t a, vint32m1_t b) {
  return a & b;
}

// CHECK-LABEL: @and_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[AND:%.*]] = and <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 1 x i64> [[AND]]
//
vint64m1_t and_i64(vint64m1_t a, vint64m1_t b) {
  return a & b;
}

// CHECK-LABEL: @and_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[AND:%.*]] = and <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 8 x i8> [[AND]]
//
vuint8m1_t and_u8(vuint8m1_t a, vuint8m1_t b) {
  return a & b;
}

// CHECK-LABEL: @and_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[AND:%.*]] = and <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 4 x i16> [[AND]]
//
vuint16m1_t and_u16(vuint16m1_t a, vuint16m1_t b) {
  return a & b;
}

// CHECK-LABEL: @and_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[AND:%.*]] = and <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 2 x i32> [[AND]]
//
vuint32m1_t and_u32(vuint32m1_t a, vuint32m1_t b) {
  return a & b;
}

// CHECK-LABEL: @and_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[AND:%.*]] = and <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 1 x i64> [[AND]]
//
vuint64m1_t and_u64(vuint64m1_t a, vuint64m1_t b) {
  return a & b;
}

// OR

// CHECK-LABEL: @or_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[OR:%.*]] = or <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 8 x i8> [[OR]]
//
vint8m1_t or_i8(vint8m1_t a, vint8m1_t b) {
  return a | b;
}

// CHECK-LABEL: @or_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[OR:%.*]] = or <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 4 x i16> [[OR]]
//
vint16m1_t or_i16(vint16m1_t a, vint16m1_t b) {
  return a | b;
}

// CHECK-LABEL: @or_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[OR:%.*]] = or <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 2 x i32> [[OR]]
//
vint32m1_t or_i32(vint32m1_t a, vint32m1_t b) {
  return a | b;
}

// CHECK-LABEL: @or_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[OR:%.*]] = or <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 1 x i64> [[OR]]
//
vint64m1_t or_i64(vint64m1_t a, vint64m1_t b) {
  return a | b;
}

// CHECK-LABEL: @or_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[OR:%.*]] = or <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 8 x i8> [[OR]]
//
vuint8m1_t or_u8(vuint8m1_t a, vuint8m1_t b) {
  return a | b;
}

// CHECK-LABEL: @or_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[OR:%.*]] = or <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 4 x i16> [[OR]]
//
vuint16m1_t or_u16(vuint16m1_t a, vuint16m1_t b) {
  return a | b;
}

// CHECK-LABEL: @or_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[OR:%.*]] = or <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 2 x i32> [[OR]]
//
vuint32m1_t or_u32(vuint32m1_t a, vuint32m1_t b) {
  return a | b;
}

// CHECK-LABEL: @or_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[OR:%.*]] = or <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 1 x i64> [[OR]]
//
vuint64m1_t or_u64(vuint64m1_t a, vuint64m1_t b) {
  return a | b;
}

// XOR

// CHECK-LABEL: @xor_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[XOR:%.*]] = xor <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 8 x i8> [[XOR]]
//
vint8m1_t xor_i8(vint8m1_t a, vint8m1_t b) {
  return a ^ b;
}

// CHECK-LABEL: @xor_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[XOR:%.*]] = xor <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 4 x i16> [[XOR]]
//
vint16m1_t xor_i16(vint16m1_t a, vint16m1_t b) {
  return a ^ b;
}

// CHECK-LABEL: @xor_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[XOR:%.*]] = xor <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 2 x i32> [[XOR]]
//
vint32m1_t xor_i32(vint32m1_t a, vint32m1_t b) {
  return a ^ b;
}

// CHECK-LABEL: @xor_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[XOR:%.*]] = xor <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 1 x i64> [[XOR]]
//
vint64m1_t xor_i64(vint64m1_t a, vint64m1_t b) {
  return a ^ b;
}

// CHECK-LABEL: @xor_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[XOR:%.*]] = xor <vscale x 8 x i8> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 8 x i8> [[XOR]]
//
vuint8m1_t xor_u8(vuint8m1_t a, vuint8m1_t b) {
  return a ^ b;
}

// CHECK-LABEL: @xor_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[XOR:%.*]] = xor <vscale x 4 x i16> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 4 x i16> [[XOR]]
//
vuint16m1_t xor_u16(vuint16m1_t a, vuint16m1_t b) {
  return a ^ b;
}

// CHECK-LABEL: @xor_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[XOR:%.*]] = xor <vscale x 2 x i32> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 2 x i32> [[XOR]]
//
vuint32m1_t xor_u32(vuint32m1_t a, vuint32m1_t b) {
  return a ^ b;
}

// CHECK-LABEL: @xor_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[XOR:%.*]] = xor <vscale x 1 x i64> [[A:%.*]], [[B:%.*]]
// CHECK-NEXT:    ret <vscale x 1 x i64> [[XOR]]
//
vuint64m1_t xor_u64(vuint64m1_t a, vuint64m1_t b) {
  return a ^ b;
}

// NEG

// CHECK-LABEL: @not_i8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NOT:%.*]] = xor <vscale x 8 x i8> [[A:%.*]], shufflevector (<vscale x 8 x i8> insertelement (<vscale x 8 x i8> poison, i8 -1, i64 0), <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer)
// CHECK-NEXT:    ret <vscale x 8 x i8> [[NOT]]
//
vint8m1_t not_i8(vint8m1_t a) {
  return ~a;
}

// CHECK-LABEL: @not_i16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NOT:%.*]] = xor <vscale x 4 x i16> [[A:%.*]], shufflevector (<vscale x 4 x i16> insertelement (<vscale x 4 x i16> poison, i16 -1, i64 0), <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer)
// CHECK-NEXT:    ret <vscale x 4 x i16> [[NOT]]
//
vint16m1_t not_i16(vint16m1_t a) {
  return ~a;
}

// CHECK-LABEL: @not_i32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NOT:%.*]] = xor <vscale x 2 x i32> [[A:%.*]], shufflevector (<vscale x 2 x i32> insertelement (<vscale x 2 x i32> poison, i32 -1, i64 0), <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer)
// CHECK-NEXT:    ret <vscale x 2 x i32> [[NOT]]
//
vint32m1_t not_i32(vint32m1_t a) {
  return ~a;
}

// CHECK-LABEL: @not_i64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NOT:%.*]] = xor <vscale x 1 x i64> [[A:%.*]], shufflevector (<vscale x 1 x i64> insertelement (<vscale x 1 x i64> poison, i64 -1, i64 0), <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer)
// CHECK-NEXT:    ret <vscale x 1 x i64> [[NOT]]
//
vint64m1_t not_i64(vint64m1_t a) {
  return ~a;
}

// CHECK-LABEL: @not_u8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NOT:%.*]] = xor <vscale x 8 x i8> [[A:%.*]], shufflevector (<vscale x 8 x i8> insertelement (<vscale x 8 x i8> poison, i8 -1, i64 0), <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer)
// CHECK-NEXT:    ret <vscale x 8 x i8> [[NOT]]
//
vuint8m1_t not_u8(vuint8m1_t a) {
  return ~a;
}

// CHECK-LABEL: @not_u16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NOT:%.*]] = xor <vscale x 4 x i16> [[A:%.*]], shufflevector (<vscale x 4 x i16> insertelement (<vscale x 4 x i16> poison, i16 -1, i64 0), <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer)
// CHECK-NEXT:    ret <vscale x 4 x i16> [[NOT]]
//
vuint16m1_t not_u16(vuint16m1_t a) {
  return ~a;
}

// CHECK-LABEL: @not_u32(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NOT:%.*]] = xor <vscale x 2 x i32> [[A:%.*]], shufflevector (<vscale x 2 x i32> insertelement (<vscale x 2 x i32> poison, i32 -1, i64 0), <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer)
// CHECK-NEXT:    ret <vscale x 2 x i32> [[NOT]]
//
vuint32m1_t not_u32(vuint32m1_t a) {
  return ~a;
}

// CHECK-LABEL: @not_u64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NOT:%.*]] = xor <vscale x 1 x i64> [[A:%.*]], shufflevector (<vscale x 1 x i64> insertelement (<vscale x 1 x i64> poison, i64 -1, i64 0), <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer)
// CHECK-NEXT:    ret <vscale x 1 x i64> [[NOT]]
//
vuint64m1_t not_u64(vuint64m1_t a) {
  return ~a;
}

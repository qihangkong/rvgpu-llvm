; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN: llc < %s -mtriple=riscv64 -mattr=+v,+zfh,+zvfh | FileCheck %s

%struct.xyzt = type { i32, i32, i32, i32 }

define dso_local void @loop_xyzt(ptr noalias nocapture noundef writeonly %dst, ptr nocapture noundef readonly %a, ptr nocapture noundef readonly %b) {
; CHECK-LABEL: loop_xyzt:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    csrr a4, vlenb
; CHECK-NEXT:    srli a3, a4, 1
; CHECK-NEXT:    slli a4, a4, 3
; CHECK-NEXT:    li a5, 1024
; CHECK-NEXT:    vsetvli a6, zero, e32, m2, ta, ma
; CHECK-NEXT:  .LBB0_1: # %vector.body
; CHECK-NEXT:    # =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    vlseg4e32.v v8, (a1)
; CHECK-NEXT:    vlseg4e32.v v16, (a2)
; CHECK-NEXT:    vadd.vv v8, v16, v8
; CHECK-NEXT:    vsub.vv v10, v10, v18
; CHECK-NEXT:    vsll.vv v12, v12, v20
; CHECK-NEXT:    vsra.vv v14, v14, v22
; CHECK-NEXT:    vsseg4e32.v v8, (a0)
; CHECK-NEXT:    sub a5, a5, a3
; CHECK-NEXT:    add a0, a0, a4
; CHECK-NEXT:    add a2, a2, a4
; CHECK-NEXT:    add a1, a1, a4
; CHECK-NEXT:    bnez a5, .LBB0_1
; CHECK-NEXT:  # %bb.2: # %for.cond.cleanup
; CHECK-NEXT:    ret
entry:
  %0 = tail call i64 @llvm.vscale.i64()
  %1 = shl nuw nsw i64 %0, 2
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %2 = getelementptr inbounds %struct.xyzt, ptr %a, i64 %index
  %wide.vec = load <vscale x 16 x i32>, ptr %2, align 4
  %root.strided.vec = tail call { <vscale x 8 x i32>, <vscale x 8 x i32> } @llvm.experimental.vector.deinterleave2.nxv16i32(<vscale x 16 x i32> %wide.vec)
  %3 = extractvalue { <vscale x 8 x i32>, <vscale x 8 x i32> } %root.strided.vec, 0
  %4 = extractvalue { <vscale x 8 x i32>, <vscale x 8 x i32> } %root.strided.vec, 1
  %root.strided.vec55 = tail call { <vscale x 4 x i32>, <vscale x 4 x i32> } @llvm.experimental.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> %3)
  %5 = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } %root.strided.vec55, 0
  %6 = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } %root.strided.vec55, 1
  %root.strided.vec56 = tail call { <vscale x 4 x i32>, <vscale x 4 x i32> } @llvm.experimental.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> %4)
  %7 = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } %root.strided.vec56, 0
  %8 = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } %root.strided.vec56, 1
  %9 = getelementptr inbounds %struct.xyzt, ptr %b, i64 %index
  %wide.vec57 = load <vscale x 16 x i32>, ptr %9, align 4
  %root.strided.vec58 = tail call { <vscale x 8 x i32>, <vscale x 8 x i32> } @llvm.experimental.vector.deinterleave2.nxv16i32(<vscale x 16 x i32> %wide.vec57)
  %10 = extractvalue { <vscale x 8 x i32>, <vscale x 8 x i32> } %root.strided.vec58, 0
  %11 = extractvalue { <vscale x 8 x i32>, <vscale x 8 x i32> } %root.strided.vec58, 1
  %root.strided.vec59 = tail call { <vscale x 4 x i32>, <vscale x 4 x i32> } @llvm.experimental.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> %10)
  %12 = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } %root.strided.vec59, 0
  %13 = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } %root.strided.vec59, 1
  %root.strided.vec60 = tail call { <vscale x 4 x i32>, <vscale x 4 x i32> } @llvm.experimental.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> %11)
  %14 = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } %root.strided.vec60, 0
  %15 = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } %root.strided.vec60, 1
  %16 = add nsw <vscale x 4 x i32> %12, %5
  %17 = sub nsw <vscale x 4 x i32> %6, %13
  %18 = shl <vscale x 4 x i32> %7, %14
  %19 = ashr <vscale x 4 x i32> %8, %15
  %20 = getelementptr inbounds %struct.xyzt, ptr %dst, i64 %index
  %interleaved.vec = tail call <vscale x 8 x i32> @llvm.experimental.vector.interleave2.nxv8i32(<vscale x 4 x i32> %16, <vscale x 4 x i32> %17)
  %interleaved.vec61 = tail call <vscale x 8 x i32> @llvm.experimental.vector.interleave2.nxv8i32(<vscale x 4 x i32> %18, <vscale x 4 x i32> %19)
  %interleaved.vec62 = tail call <vscale x 16 x i32> @llvm.experimental.vector.interleave2.nxv16i32(<vscale x 8 x i32> %interleaved.vec, <vscale x 8 x i32> %interleaved.vec61)
  store <vscale x 16 x i32> %interleaved.vec62, ptr %20, align 4
  %index.next = add nuw i64 %index, %1
  %21 = icmp eq i64 %index.next, 1024
  br i1 %21, label %for.cond.cleanup, label %vector.body

for.cond.cleanup:                                 ; preds = %vector.body
  ret void
}
